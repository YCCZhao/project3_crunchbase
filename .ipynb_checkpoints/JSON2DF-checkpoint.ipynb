{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Feature Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = glob.glob(\"person/*\")\n",
    "\n",
    "key_set = set()\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        js = {\"not-working\": entity}\n",
    "    for key in list(js.keys()):\n",
    "        if key not in key_set:\n",
    "            key_set.add(key)\n",
    "\n",
    "pickle.dump(key_set, open(\"person_key_set\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = glob.glob(\"company/*\")\n",
    "\n",
    "key_set = set()\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        js = {\"not-working\": entity}\n",
    "    for key in list(js.keys()):\n",
    "        if key not in key_set:\n",
    "            key_set.add(key)\n",
    "\n",
    "pickle.dump(key_set, open(\"company_key_set\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = {}\n",
    "features['person'] = ['permalink',\n",
    "                      'first_name',\n",
    "                      'last_name',\n",
    "                      'twitter_username',\n",
    "                      'born_year',\n",
    "                      'born_month',\n",
    "                      'born_day',\n",
    "                      'birthplace',\n",
    "                      'degrees',\n",
    "                      'overview',\n",
    "                      'alias_list',\n",
    "                      'affiliation_name']\n",
    "\n",
    "features['degrees'] = ['person_permalink','degree_type', 'institution', 'subject']\n",
    "\n",
    "features['funding_round'] = ['company_permalink','round_code',\n",
    "                             'raised_amount',\n",
    "                             'raised_currency_code',\n",
    "                             'funded_year',\n",
    "                             'funded_month',\n",
    "                             'funded_day',]\n",
    "\n",
    "features['company'] = ['permalink',\n",
    "                       'name',\n",
    "                       'category_code',\n",
    "                       'description',\n",
    "                       'overview',\n",
    "                       'twitter_username',\n",
    "                       'alias_list',\n",
    "                       'number_of_employees',\n",
    "                       'total_money_raised',\n",
    "                       'founded_year',\n",
    "                       'founded_month',\n",
    "                       'founded_day',\n",
    "                       'deadpooled_year',\n",
    "                       'deadpooled_month',\n",
    "                       'deadpooled_day',\n",
    "                       'ipo',\n",
    "                       'acquisition']\n",
    "\n",
    "features['competition'] = ['competitor', 'permalink']\n",
    "\n",
    "features['relationship'] = ['person_permalink',\n",
    "                            'company_permalink',\n",
    "                            'is_past',\n",
    "                            'title']\n",
    "\n",
    "features['milestones'] = ['stoneable',\n",
    "                          'description',\n",
    "                          'stoned_year',\n",
    "                          'stoned_month',\n",
    "                          'stoned_day',\n",
    "                          'stoneable_type',\n",
    "                          'stoned_acquirer',\n",
    "                          'stoned_value',\n",
    "                          'stoned_value_type']\n",
    "\n",
    "features['acquisition'] = ['company_permalink',\n",
    "                           'acquired_day',\n",
    "                          'acquired_month',\n",
    "                          'acquired_year',\n",
    "                          'acquiring_company',\n",
    "                          'price_amount',\n",
    "                          'price_currency_code',\n",
    "                          'source_description',\n",
    "                          'term_code']\n",
    "\n",
    "features['ipo'] = ['company_permalink',\n",
    "                   'valuation_amount', \n",
    "                   'valuation_currency_code', \n",
    "                   'pub_year',\n",
    "                   'pub_month',\n",
    "                   'pub_day',\n",
    "                   'stock_symbol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Information From JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('foo.txt', 'w')\n",
    "\n",
    "entities = glob.glob(\"person/*\")\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    string = \"\"\n",
    "    for feature in features['person']:\n",
    "        \n",
    "        if not js[feature]:   \n",
    "            string += \"None\" + '\\t'\n",
    "        \n",
    "        #elif features == \"overview\":\n",
    "        #    string += \"%r\"%str(js[feature]) + '\\t'\n",
    "        \n",
    "        else:\n",
    "            string += \"%r\"%str(js[feature]) + '\\t'\n",
    "    \n",
    "    string += '\\n'\n",
    "    \n",
    "    file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('foo.txt', 'w')\n",
    "\n",
    "entities = glob.glob(\"person/*\")\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    for degree in js['degrees']:\n",
    "        \n",
    "        string = \"%r\"%js['permalink'] + '\\t'\n",
    "        try:\n",
    "            for feature in features['degrees']:       \n",
    "                string += \"%r\"%degree[feature] + '\\t'\n",
    "        except:\n",
    "            print(degree)\n",
    "    \n",
    "        string += '\\n'\n",
    "        file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('foo.txt', 'w')\n",
    "\n",
    "entities = glob.glob(\"company/*\")\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    string = \"\"\n",
    "    for feature in features['company']:\n",
    "        \n",
    "        if not js[feature]:   \n",
    "            string += \"None\" + '\\t'\n",
    "\n",
    "        \n",
    "        #elif features == \"overview\":\n",
    "        #    string += \"%r\"%str(js[feature]) + '\\t'\n",
    "        \n",
    "        else:\n",
    "            string += \"%r\"%str(js[feature]) + '\\t'\n",
    "    \n",
    "    string += '\\n'\n",
    "    \n",
    "    file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('foo.txt', 'w')\n",
    "\n",
    "entities = glob.glob(\"company/*\")\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    for milestone in js['milestones']:\n",
    "        string = \"%r\"%milestone['stoneable']['permalink'] + '\\t'\n",
    "        for feature in features['milestones']:\n",
    "            string += \"%r\"%milestone[feature] + '\\t'\n",
    "    \n",
    "    \n",
    "        string = string+'\\n'\n",
    "        file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('foo.txt', 'w')\n",
    "\n",
    "entities = glob.glob(\"company/*\")\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    for funding_round in js['funding_rounds']:\n",
    "        string = \"%r\"%js['permalink'] + '\\t'\n",
    "                            \n",
    "        for feature in features['funding_round']:\n",
    "            \n",
    "            string += \"%r\"%funding_round[feature] + '\\t'\n",
    "    \n",
    "    \n",
    "        string = string+'\\n'\n",
    "        file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('foo.txt', 'w')\n",
    "\n",
    "entities = glob.glob(\"company/*\")\n",
    "\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    string = \"%r\"%js['permalink'] + '\\t'\n",
    "    \n",
    "    if not js['ipo']:\n",
    "        continue\n",
    "    for feature in features['ipo']:\n",
    "        if feature == 'acquiring_company':\n",
    "            string += \"%r\"%js['acquisition']['acquiring_company']['permalink'] + '\\t'\n",
    "        else:\n",
    "            string += \"%r\"%js['ipo'][feature] + '\\t'\n",
    "    \n",
    "    string = string+'\\n'\n",
    "    file.write(string)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = glob.glob(\"company/*\")\n",
    "\n",
    "key_set = []\n",
    "for entity in entities:\n",
    "    try:\n",
    "        js = json.loads(pickle.load(open(entity,\"rb\")))\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    for foo in js['competitions']:\n",
    "        bar = foo['competitor']\n",
    "        for key in list(bar.keys()):\n",
    "            if key not in key_set:\n",
    "                key_set.append(key)\n",
    "    \n",
    "\n",
    "key_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipo = pd.read_csv('foo.txt', delimiter='\\t', header=None)\n",
    "rename_col = dict(zip(range(len(features['ipo'])), features['ipo']))\n",
    "ipo = ipo.rename(columns=rename_col)\n",
    "ipo = ipo.drop(7, axis=1)\n",
    "ipo_df = ipo\n",
    "pickle.dump(ipo_df, open(\"ipo_df\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ipo_df.columns:\n",
    "    ipo_df[col] = ipo_df[col].str.strip(\"'\")\n",
    "ipo_df = ipo_df.replace('None', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(ipo_df, open(\"ipo_clean_df\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in relationship_person_df.columns:\n",
    "    relationship_person_df[col] = relationship_person_df[col].str.strip(\"'\")\n",
    "    relationship_company_df[col] = relationship_company_df[col].str.strip(\"'\")\n",
    "relationship_df = pd.concat([relationship_person_df,relationship_company_df])\n",
    "relationship_df.drop_duplicates(['person_permalink', 'company_permalink'])\n",
    "\n",
    "for col in person_df.columns:\n",
    "    person_df[col] = person_df[col].str.strip(\"'\")\n",
    "person_df = person_df.replace('None', np.NaN)\n",
    "\n",
    "for col in degrees_df.columns:\n",
    "    degrees_df[col] = degrees_df[col].str.strip(\"'\")\n",
    "degrees_df = degrees_df.replace('None', np.NaN)\n",
    "\n",
    "\n",
    "pickle.dump(relationship_df, open('relationship_clean_df','wb'))\n",
    "pickle.dump(degrees_df, open('degrees_clean_df','wb'))\n",
    "pickle.dump(person_df, open('person_clean_df','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
